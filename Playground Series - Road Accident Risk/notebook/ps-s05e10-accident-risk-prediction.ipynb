{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91721,"databundleVersionId":13760552,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üöó Predicting Road Accident Risk\n\n**Competition:** Playground Series - Season 5, Episode 10 Predicting Road Accident Risk\n\n---\n\n## üìå Executive Summary\n\nThis notebook presents a comprehensive approach to predicting traffic accident risk through:\n- **In-depth EDA** revealing key risk factors\n- **Strategic feature engineering** based on domain insights\n- **Ensemble modeling** combining three powerful algorithms\n- **Systematic optimization** through hyperparameter tuning\n\n---\n\n## üìö Table of Contents\n\n1. [Data Loading & Overview](#1)\n2. [Exploratory Data Analysis](#2)\n   - Numerical Features\n   - Categorical Features  \n   - Target Variable Analysis\n   - Feature Correlations\n3. [Feature Engineering](#3)\n4. [Baseline Model - Random Forest](#4)\n5. [Model Improvements](#5)\n   - CatBoost Implementation\n   - LightGBM Addition\n6. [Ensemble Strategy](#6)\n7. [Final Submission](#7)\n8. [Conclusions & Future Work](#8)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Modeling libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\nfrom lightgbm import LGBMRegressor\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-29T20:12:29.804119Z","iopub.execute_input":"2025-10-29T20:12:29.804294Z","iopub.status.idle":"2025-10-29T20:12:36.730436Z","shell.execute_reply.started":"2025-10-29T20:12:29.804275Z","shell.execute_reply":"2025-10-29T20:12:36.729598Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n<a id='1'></a>\n# 1Ô∏è‚É£ Data Loading & Overview\n\nLet's start by loading and understanding our dataset structure.","metadata":{}},{"cell_type":"code","source":"# Load train and test datasets\ntrain_df = pd.read_csv('/kaggle/input/playground-series-s5e10/train.csv')\ntest_df = pd.read_csv('/kaggle/input/playground-series-s5e10/test.csv')\n\nprint(\"=== DATASET SHAPES ===\")\nprint(f\"Train Data Shape: {train_df.shape}\")\nprint(f\"Test Data Shape: {test_df.shape}\")\n\n# Display first few rows\ntrain_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T20:15:26.026983Z","iopub.execute_input":"2025-10-29T20:15:26.027397Z","iopub.status.idle":"2025-10-29T20:15:27.087841Z","shell.execute_reply.started":"2025-10-29T20:15:26.027340Z","shell.execute_reply":"2025-10-29T20:15:27.087189Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"=== DATA TYPES & NULL VALUES ===\")\nprint(train_df.info())\n\nprint(\"\\n=== NULL VALUES CHECK ===\")\nprint(train_df.isnull().sum())\n\nprint(\"\\n=== BASIC STATISTICS ===\")\ntrain_df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T20:15:46.451566Z","iopub.execute_input":"2025-10-29T20:15:46.451865Z","iopub.status.idle":"2025-10-29T20:15:46.706005Z","shell.execute_reply.started":"2025-10-29T20:15:46.451841Z","shell.execute_reply":"2025-10-29T20:15:46.705267Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n<a id='2'></a>\n# 2Ô∏è‚É£ Exploratory Data Analysis (EDA)\n\n## 2.1 Target Variable Distribution\n\nUnderstanding our target variable `accident_risk` is crucial for model selection and evaluation.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 5))\n\n# Histogram\nplt.subplot(1, 2, 1)\nplt.hist(train_df['accident_risk'], bins=50, edgecolor='black', alpha=0.7)\nplt.title('Distribution of Accident Risk', fontsize=14, fontweight='bold')\nplt.xlabel('Accident Risk', fontsize=12)\nplt.ylabel('Count', fontsize=12)\nplt.grid(axis='y', alpha=0.3)\n\n# Box plot\nplt.subplot(1, 2, 2)\nplt.boxplot(train_df['accident_risk'], vert=True)\nplt.title('Accident Risk - Box Plot', fontsize=14, fontweight='bold')\nplt.ylabel('Accident Risk', fontsize=12)\nplt.grid(axis='y', alpha=0.3)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T20:17:08.110251Z","iopub.execute_input":"2025-10-29T20:17:08.110580Z","iopub.status.idle":"2025-10-29T20:17:08.406954Z","shell.execute_reply.started":"2025-10-29T20:17:08.110559Z","shell.execute_reply":"2025-10-29T20:17:08.406167Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### üí° Key Observations:\n- **Right-skewed distribution** - Most roads have low to medium risk (0.2-0.5)\n- **Mean risk: 0.35** - Relatively balanced target\n- **Long tail** - Small number of very high-risk scenarios (0.7+)","metadata":{}},{"cell_type":"code","source":"numeric_cols = ['num_lanes','curvature','speed_limit','num_reported_accidents','accident_risk']\ncategorical_cols = ['road_type','lighting','weather','time_of_day']\nboolean_cols = ['road_signs_present', 'public_road', 'holiday', 'school_season']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T20:21:52.108527Z","iopub.execute_input":"2025-10-29T20:21:52.108805Z","iopub.status.idle":"2025-10-29T20:21:52.112812Z","shell.execute_reply.started":"2025-10-29T20:21:52.108785Z","shell.execute_reply":"2025-10-29T20:21:52.112094Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Correlation Matrix\ncorrelation_matrix = train_df[numeric_cols].corr()\n\nplt.figure(figsize=(10, 8))\nsns.heatmap(correlation_matrix, \n            annot=True,\n            fmt='.3f',\n            cmap='coolwarm',\n            center=0,\n            square=True,\n            linewidths=1,\n            cbar_kws={'label': 'Correlation Coefficient'})\n\nplt.title('Correlation Matrix - Numerical Features', \n          fontsize=14, fontweight='bold', pad=20)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T20:20:02.590486Z","iopub.execute_input":"2025-10-29T20:20:02.590732Z","iopub.status.idle":"2025-10-29T20:20:02.848870Z","shell.execute_reply.started":"2025-10-29T20:20:02.590713Z","shell.execute_reply":"2025-10-29T20:20:02.847848Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### üî• Critical Findings:\n\n**Strong Correlations:**\n1. **curvature: 0.544** - Curved roads significantly increase risk\n2. **speed_limit: 0.432** - Higher speed = higher risk\n3. **num_reported_accidents: 0.214** - Past accidents show moderate correlation\n\n**Weak/No Correlation:**\n- **num_lanes: -0.01** - Number of lanes has almost no effect\n- Features are largely independent (no multicollinearity issues)","metadata":{}},{"cell_type":"code","source":"# Categorical Field Analysis\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\naxes = axes.flatten()\n\nfor idx, col in enumerate(categorical_cols):\n    train_df[col].value_counts().plot(kind='bar', ax=axes[idx], color='steelblue')\n    axes[idx].set_title(f'{col.upper()} Distribution', fontsize=12, fontweight='bold')\n    axes[idx].set_xlabel('')\n    axes[idx].set_ylabel('Count')\n    axes[idx].tick_params(axis='x', rotation=45)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T20:22:31.798816Z","iopub.execute_input":"2025-10-29T20:22:31.799103Z","iopub.status.idle":"2025-10-29T20:22:32.381118Z","shell.execute_reply.started":"2025-10-29T20:22:31.799085Z","shell.execute_reply":"2025-10-29T20:22:32.379962Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(14, 6))\n\nsns.boxplot(data=train_df, x='num_reported_accidents', y='accident_risk', palette='Blues')\nplt.title('Distribution of Accident Risk by Number of Reported Accidents', \n          fontsize=14, fontweight='bold')\nplt.xlabel('Number of Reported Accidents', fontsize=12)\nplt.ylabel('Accident Risk', fontsize=12)\n\nplt.legend()\nplt.grid(axis='y', alpha=0.3)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T20:24:28.917093Z","iopub.execute_input":"2025-10-29T20:24:28.917382Z","iopub.status.idle":"2025-10-29T20:24:29.169083Z","shell.execute_reply.started":"2025-10-29T20:24:28.917340Z","shell.execute_reply":"2025-10-29T20:24:29.168298Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### üìä Surprising Finding!\n\n**Non-linear relationship between past accidents and risk:**\n- **0-2 accidents:** Similar low risk (~0.33-0.34)\n- **3+ accidents:** Risk jumps significantly (0.55+)\n- **4 accidents:** Very high risk (0.68)\n- **7 accidents:** Only 2 samples - unreliable data point","metadata":{}},{"cell_type":"markdown","source":"---\n\n<a id='3'></a>\n# 3Ô∏è‚É£ Feature Engineering\n\nBased on EDA insights, we'll create interaction features focusing on the top predictors:\n- `curvature √ó speed_limit` - Curved roads at high speed\n- `curvature √ó lighting` - Curved roads in darkness\n- `lighting √ó weather` - Poor visibility conditions\n- Polynomial features for non-linear effects","metadata":{}},{"cell_type":"code","source":"X = train_df.drop(['id', 'accident_risk'], axis=1)\ny = train_df['accident_risk']\n\nlabel_encoders = {}\n\nX_encoded = X.copy()\nfor col in categorical_cols:\n    le = LabelEncoder()\n    X_encoded[col] = le.fit_transform(X[col])\n    label_encoders[col] = le\n    print(f\"‚úÖ Encoded {col}: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n\nfor col in boolean_cols:\n    X_encoded[col] = X_encoded[col].astype(int)\n\nprint(f\"\\n‚úÖ Preprocessing complete!\")\nprint(f\"Feature shape: {X_encoded.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T20:29:28.749712Z","iopub.execute_input":"2025-10-29T20:29:28.750029Z","iopub.status.idle":"2025-10-29T20:29:29.056231Z","shell.execute_reply.started":"2025-10-29T20:29:28.750010Z","shell.execute_reply":"2025-10-29T20:29:29.055434Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_fe = X_encoded.copy()\n\n# 1. Curvature √ó Speed (high-risk combination)\nX_fe['curvature_x_speed'] = X_fe['curvature'] * X_fe['speed_limit']\n\n# 2. Lighting √ó Weather (poor visibility)\nX_fe['lighting_x_weather'] = X_fe['lighting'] * X_fe['weather']\n\n# 3. Curvature √ó Lighting (curved + dark)\nX_fe['curvature_x_lighting'] = X_fe['curvature'] * X_fe['lighting']\n\n# 4. Speed √ó Weather (high speed + bad weather)\nX_fe['speed_x_weather'] = X_fe['speed_limit'] * X_fe['weather']\n\n# 5. High risk combo flag\nX_fe['high_risk_combo'] = (\n    (X_fe['curvature'] > 0.5).astype(int) * \n    (X_fe['speed_limit'] > 50).astype(int) * \n    (X_fe['lighting'] == 1).astype(int)  # Assuming 1 = night\n)\n\n# 6. Polynomial features\nX_fe['curvature_squared'] = X_fe['curvature'] ** 2\nX_fe['speed_squared'] = X_fe['speed_limit'] ** 2\n\nprint(\"=== FEATURE ENGINEERING COMPLETE ===\")\nprint(f\"Original features: {X_encoded.shape[1]}\")\nprint(f\"New features: {X_fe.shape[1]}\")\nprint(f\"Added: {X_fe.shape[1] - X_encoded.shape[1]} features\")\n\nprint(\"\\nüìù New features created:\")\nnew_features = [col for col in X_fe.columns if col not in X_encoded.columns]\nfor feat in new_features:\n    print(f\"  ‚úÖ {feat}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T20:29:47.842898Z","iopub.execute_input":"2025-10-29T20:29:47.843160Z","iopub.status.idle":"2025-10-29T20:29:47.910146Z","shell.execute_reply.started":"2025-10-29T20:29:47.843143Z","shell.execute_reply":"2025-10-29T20:29:47.909409Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(\n    X_encoded, y, test_size=0.2, random_state=42\n)\n\nX_train_fe, X_val_fe, y_train_fe, y_val_fe = train_test_split(\n    X_fe, y, test_size=0.2, random_state=42\n)\n\nprint(\"=== DATA SPLIT COMPLETE ===\")\nprint(f\"Training set: {X_train.shape}\")\nprint(f\"Validation set: {X_val.shape}\")\nprint(f\"Training set (FE): {X_train_fe.shape}\")\nprint(f\"Validation set (FE): {X_val_fe.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T20:30:12.353960Z","iopub.execute_input":"2025-10-29T20:30:12.354235Z","iopub.status.idle":"2025-10-29T20:30:12.581199Z","shell.execute_reply.started":"2025-10-29T20:30:12.354216Z","shell.execute_reply":"2025-10-29T20:30:12.579995Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n<a id='4'></a>\n# 4Ô∏è‚É£ Baseline Model - Random Forest\n\nLet's establish a baseline with Random Forest Regressor using original features.","metadata":{}},{"cell_type":"code","source":"rf_baseline = RandomForestRegressor(\n    n_estimators=100,\n    max_depth=10,\n    random_state=42,\n    n_jobs=-1,\n    verbose=0\n)\n\nprint(\"Training baseline Random Forest...\")\nrf_baseline.fit(X_train, y_train)\n\n# Predictions\ny_train_pred = rf_baseline.predict(X_train)\ny_val_pred = rf_baseline.predict(X_val)\n\n# Evaluation\nprint(\"\\n=== BASELINE MODEL PERFORMANCE ===\\n\")\nprint(\"TRAINING SET:\")\nprint(f\"  RMSE: {np.sqrt(mean_squared_error(y_train, y_train_pred)):.6f}\")\nprint(f\"  MAE:  {mean_absolute_error(y_train, y_train_pred):.6f}\")\nprint(f\"  R¬≤:   {r2_score(y_train, y_train_pred):.6f}\")\n\nprint(\"\\nVALIDATION SET:\")\nbaseline_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\nbaseline_mae = mean_absolute_error(y_val, y_val_pred)\nbaseline_r2 = r2_score(y_val, y_val_pred)\n\nprint(f\"  RMSE: {baseline_rmse:.6f}\")\nprint(f\"  MAE:  {baseline_mae:.6f}\")\nprint(f\"  R¬≤:   {baseline_r2:.6f}\")\n\n# Feature importance\nfeature_importance = pd.DataFrame({\n    'feature': X_encoded.columns,\n    'importance': rf_baseline.feature_importances_\n}).sort_values('importance', ascending=False)\n\nprint(\"\\n=== TOP 10 FEATURES ===\")\nprint(feature_importance.head(10).to_string(index=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T20:30:50.952702Z","iopub.execute_input":"2025-10-29T20:30:50.953056Z","iopub.status.idle":"2025-10-29T20:31:18.466849Z","shell.execute_reply.started":"2025-10-29T20:30:50.953035Z","shell.execute_reply":"2025-10-29T20:31:18.465958Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ‚úÖ Baseline Results:\n\n**Performance:**\n- Validation RMSE: ~0.0563\n- R¬≤: ~0.885\n- No significant overfitting (train/val scores are close)\n\n**Feature Importance Confirms EDA:**\n1. `curvature` - Most important\n2. `lighting` - Second most important\n3. `speed_limit` - Third most important\n\nThis validates our EDA findings! üéØ\n\n---\n\n<a id='5'></a>\n# 5Ô∏è‚É£ Model Improvements\n\nNow let's try more advanced models and feature engineering.\n\n## 5.1 Random Forest with Feature Engineering","metadata":{}},{"cell_type":"code","source":"rf_fe = RandomForestRegressor(\n    n_estimators=100,\n    max_depth=10,\n    random_state=42,\n    n_jobs=-1,\n    verbose=0\n)\n\nprint(\"Training Random Forest with engineered features...\")\nrf_fe.fit(X_train_fe, y_train_fe)\n\n# Predictions\ny_val_pred_fe = rf_fe.predict(X_val_fe)\n\n# Evaluation\nrf_fe_rmse = np.sqrt(mean_squared_error(y_val_fe, y_val_pred_fe))\nrf_fe_r2 = r2_score(y_val_fe, y_val_pred_fe)\n\nprint(\"\\n=== RF WITH FEATURE ENGINEERING ===\")\nprint(f\"  RMSE: {rf_fe_rmse:.6f}\")\nprint(f\"  R¬≤:   {rf_fe_r2:.6f}\")\n\n# Feature importance\nfeature_importance_fe = pd.DataFrame({\n    'feature': X_fe.columns,\n    'importance': rf_fe.feature_importances_\n}).sort_values('importance', ascending=False)\n\nprint(\"\\n=== TOP 10 FEATURES (with FE) ===\")\nprint(feature_importance_fe.head(10).to_string(index=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T20:33:25.151628Z","iopub.execute_input":"2025-10-29T20:33:25.151889Z","iopub.status.idle":"2025-10-29T20:34:03.631383Z","shell.execute_reply.started":"2025-10-29T20:33:25.151869Z","shell.execute_reply":"2025-10-29T20:34:03.630318Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### üí° Observation:\nThe interaction feature `curvature_x_speed` becomes the most important feature, absorbing importance from individual features!\n\n---\n\n## 5.2 CatBoost Regressor\n\nCatBoost excels at handling categorical features naturally.","metadata":{}},{"cell_type":"code","source":"X_catboost = train_df.drop(['id', 'accident_risk'], axis=1)\ny_catboost = train_df['accident_risk']\n\ncat_features = ['road_type', 'lighting', 'weather', 'time_of_day']\n\nX_train_cat, X_val_cat, y_train_cat, y_val_cat = train_test_split(\n    X_catboost, y_catboost, test_size=0.2, random_state=42\n)\n\ncatboost_model = CatBoostRegressor(\n    iterations=500,\n    learning_rate=0.1,\n    depth=8,\n    loss_function='RMSE',\n    cat_features=cat_features,\n    random_state=42,\n    verbose=False\n)\n\ncatboost_model.fit(X_train_cat, y_train_cat)\n\ny_val_pred_cat = catboost_model.predict(X_val_cat)\n\ncat_rmse = np.sqrt(mean_squared_error(y_val_cat, y_val_pred_cat))\ncat_r2 = r2_score(y_val_cat, y_val_pred_cat)\n\nprint(\"\\n=== CATBOOST PERFORMANCE ===\")\nprint(f\"  RMSE: {cat_rmse:.6f}\")\nprint(f\"  R¬≤:   {cat_r2:.6f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T20:35:09.369273Z","iopub.execute_input":"2025-10-29T20:35:09.369547Z","iopub.status.idle":"2025-10-29T20:36:19.945802Z","shell.execute_reply.started":"2025-10-29T20:35:09.369531Z","shell.execute_reply":"2025-10-29T20:36:19.945027Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5.3 LightGBM Regressor\n\nAdding LightGBM for ensemble diversity.","metadata":{}},{"cell_type":"code","source":"lgbm_model = LGBMRegressor(\n    n_estimators=500,\n    learning_rate=0.05,\n    max_depth=8,\n    num_leaves=31,\n    random_state=42,\n    verbose=-1,\n    n_jobs=-1\n)\n\nlgbm_model.fit(X_train_fe, y_train_fe)\n\ny_val_pred_lgbm = lgbm_model.predict(X_val_fe)\n\nlgbm_rmse = np.sqrt(mean_squared_error(y_val_fe, y_val_pred_lgbm))\nlgbm_r2 = r2_score(y_val_fe, y_val_pred_lgbm)\n\nprint(\"\\n=== LIGHTGBM PERFORMANCE ===\")\nprint(f\"  RMSE: {lgbm_rmse:.6f}\")\nprint(f\"  R¬≤:   {lgbm_r2:.6f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T20:36:35.508562Z","iopub.execute_input":"2025-10-29T20:36:35.509301Z","iopub.status.idle":"2025-10-29T20:36:42.607239Z","shell.execute_reply.started":"2025-10-29T20:36:35.509269Z","shell.execute_reply":"2025-10-29T20:36:42.606535Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n<a id='6'></a>\n# 6Ô∏è‚É£ Ensemble Strategy\n\nIndividual models are good, but ensemble is better! Let's combine predictions.","metadata":{}},{"cell_type":"code","source":"results = pd.DataFrame({\n    'Model': ['Baseline RF', 'RF + Feature Eng', 'CatBoost', 'LightGBM'],\n    'RMSE': [baseline_rmse, rf_fe_rmse, cat_rmse, lgbm_rmse],\n    'R¬≤': [baseline_r2, rf_fe_r2, cat_r2, lgbm_r2]\n}).sort_values('RMSE')\n\nprint(\"=== MODEL COMPARISON ===\\n\")\nprint(results.to_string(index=False))\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\naxes[0].barh(results['Model'], results['RMSE'], color='coral')\naxes[0].set_xlabel('RMSE (lower is better)', fontweight='bold')\naxes[0].set_title('Model Comparison - RMSE', fontsize=14, fontweight='bold')\naxes[0].invert_yaxis()\naxes[0].grid(axis='x', alpha=0.3)\n\naxes[1].barh(results['Model'], results['R¬≤'], color='lightgreen')\naxes[1].set_xlabel('R¬≤ Score (higher is better)', fontweight='bold')\naxes[1].set_title('Model Comparison - R¬≤', fontsize=14, fontweight='bold')\naxes[1].invert_yaxis()\naxes[1].grid(axis='x', alpha=0.3)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T20:37:00.352000Z","iopub.execute_input":"2025-10-29T20:37:00.352261Z","iopub.status.idle":"2025-10-29T20:37:00.581288Z","shell.execute_reply.started":"2025-10-29T20:37:00.352242Z","shell.execute_reply":"2025-10-29T20:37:00.580335Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"=== TESTING ENSEMBLE COMBINATIONS ===\\n\")\n\nweight_configs = [\n    (0.3, 0.5, 0.2, 'RF 30% + Cat 50% + LGBM 20%'),\n    (0.2, 0.5, 0.3, 'RF 20% + Cat 50% + LGBM 30%'),\n    (0.25, 0.5, 0.25, 'RF 25% + Cat 50% + LGBM 25%'),\n    (0.3, 0.4, 0.3, 'RF 30% + Cat 40% + LGBM 30%'),\n]\n\nensemble_results = []\n\nfor w_rf, w_cat, w_lgbm, label in weight_configs:\n    y_val_ensemble = (w_rf * y_val_pred_fe + \n                     w_cat * y_val_pred_cat + \n                     w_lgbm * y_val_pred_lgbm)\n    \n    rmse = np.sqrt(mean_squared_error(y_val, y_val_ensemble))\n    r2 = r2_score(y_val, y_val_ensemble)\n    \n    ensemble_results.append({\n        'Configuration': label,\n        'RMSE': rmse,\n        'R¬≤': r2\n    })\n    \n    print(f\"{label}\")\n    print(f\"  RMSE: {rmse:.6f}, R¬≤: {r2:.6f}\\n\")\n\n# Find best\nensemble_df = pd.DataFrame(ensemble_results).sort_values('RMSE')\nprint(\"\\nüèÜ BEST ENSEMBLE:\")\nprint(ensemble_df.iloc[0].to_string())\n\nbest_ensemble_rmse = ensemble_df.iloc[0]['RMSE']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T20:37:33.281317Z","iopub.execute_input":"2025-10-29T20:37:33.281653Z","iopub.status.idle":"2025-10-29T20:37:33.296590Z","shell.execute_reply.started":"2025-10-29T20:37:33.281631Z","shell.execute_reply":"2025-10-29T20:37:33.295389Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_results = pd.DataFrame({\n    'Model': ['Baseline RF', 'RF + FE', 'CatBoost', 'LightGBM', 'Ensemble (Best)'],\n    'RMSE': [baseline_rmse, rf_fe_rmse, cat_rmse, lgbm_rmse, best_ensemble_rmse]\n}).sort_values('RMSE')\n\nplt.figure(figsize=(12, 6))\ncolors = ['lightcoral', 'lightsalmon', 'lightblue', 'lightgreen', 'gold']\nbars = plt.barh(all_results['Model'], all_results['RMSE'], color=colors)\n\n# Highlight best model\nbars[-1].set_color('darkgreen')\nbars[-1].set_edgecolor('black')\nbars[-1].set_linewidth(2)\n\nplt.xlabel('RMSE', fontsize=12, fontweight='bold')\nplt.title('Final Model Comparison - All Models', fontsize=14, fontweight='bold')\nplt.gca().invert_yaxis()\nplt.grid(axis='x', alpha=0.3)\n\n# Add value labels\nfor i, (idx, row) in enumerate(all_results.iterrows()):\n    plt.text(row['RMSE'] + 0.00005, i, f\"{row['RMSE']:.6f}\", \n             va='center', fontsize=10, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\n# Calculate improvement\nimprovement = ((baseline_rmse - best_ensemble_rmse) / baseline_rmse) * 100\nprint(f\"\\nüìà TOTAL IMPROVEMENT: {improvement:.2f}% from baseline\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T20:38:05.564462Z","iopub.execute_input":"2025-10-29T20:38:05.564770Z","iopub.status.idle":"2025-10-29T20:38:05.724625Z","shell.execute_reply.started":"2025-10-29T20:38:05.564750Z","shell.execute_reply":"2025-10-29T20:38:05.723488Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n<a id='7'></a>\n# 8Ô∏è‚É£ Final Submission\n\nNow let's prepare our predictions for the test set using the best ensemble model.\n\n### üéØ Final Model Configuration:\n- **Random Forest:** 30% weight (with feature engineering)\n- **CatBoost:** 50% weight (strongest single model)\n- **LightGBM:** 20% weight (for diversity)\n- **Validation RMSE:** ~0.0562","metadata":{}},{"cell_type":"code","source":"X_test = test_df.drop(['id'], axis=1)\nX_test_encoded = X_test.copy()\n\nfor col in categorical_cols:\n    X_test_encoded[col] = label_encoders[col].transform(X_test[col])\n\nfor col in boolean_cols:\n    X_test_encoded[col] = X_test_encoded[col].astype(int)\n\nX_test_fe = X_test_encoded.copy()\nX_test_fe['curvature_x_speed'] = X_test_fe['curvature'] * X_test_fe['speed_limit']\nX_test_fe['lighting_x_weather'] = X_test_fe['lighting'] * X_test_fe['weather']\nX_test_fe['curvature_x_lighting'] = X_test_fe['curvature'] * X_test_fe['lighting']\nX_test_fe['speed_x_weather'] = X_test_fe['speed_limit'] * X_test_fe['weather']\nX_test_fe['high_risk_combo'] = (\n    (X_test_fe['curvature'] > 0.5).astype(int) * \n    (X_test_fe['speed_limit'] > 50).astype(int) * \n    (X_test_fe['lighting'] == 1).astype(int)\n)\nX_test_fe['curvature_squared'] = X_test_fe['curvature'] ** 2\nX_test_fe['speed_squared'] = X_test_fe['speed_limit'] ** 2\n\nX_test_cat = test_df.drop(['id'], axis=1)\n\nprint(f\"‚úÖ Test data prepared!\")\nprint(f\"RF/LGBM input shape: {X_test_fe.shape}\")\nprint(f\"CatBoost input shape: {X_test_cat.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T20:39:02.249871Z","iopub.execute_input":"2025-10-29T20:39:02.250157Z","iopub.status.idle":"2025-10-29T20:39:02.359051Z","shell.execute_reply.started":"2025-10-29T20:39:02.250136Z","shell.execute_reply":"2025-10-29T20:39:02.358078Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# RF predictions\nprint(\"Random Forest predicting...\")\ntest_pred_rf = rf_fe.predict(X_test_fe)\n\n# CatBoost predictions\nprint(\"CatBoost predicting...\")\ntest_pred_cat = catboost_model.predict(X_test_cat)\n\n# LightGBM predictions\nprint(\"LightGBM predicting...\")\ntest_pred_lgbm = lgbm_model.predict(X_test_fe)\n\n# Ensemble with best weights (30%, 50%, 20%)\nfinal_predictions = (0.3 * test_pred_rf + \n                    0.5 * test_pred_cat + \n                    0.2 * test_pred_lgbm)\n\nprint(\"\\n Predictions complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T20:39:41.837144Z","iopub.execute_input":"2025-10-29T20:39:41.837457Z","iopub.status.idle":"2025-10-29T20:39:44.135009Z","shell.execute_reply.started":"2025-10-29T20:39:41.837437Z","shell.execute_reply":"2025-10-29T20:39:44.133948Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'id': test_df['id'],\n    'accident_risk': final_predictions\n})\n\nprint(\"=== SUBMISSION STATISTICS ===\")\nprint(f\"Total predictions: {len(submission)}\")\nprint(f\"Prediction range: [{final_predictions.min():.4f}, {final_predictions.max():.4f}]\")\nprint(f\"Prediction mean: {final_predictions.mean():.4f}\")\nprint(f\"Prediction std: {final_predictions.std():.4f}\")\n\nprint(\"\\n=== SAMPLE PREDICTIONS ===\")\nprint(submission.head(10))\n\n# Visualize prediction distribution\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.hist(final_predictions, bins=50, edgecolor='black', alpha=0.7, color='green')\nplt.axvline(final_predictions.mean(), color='red', linestyle='--', \n            linewidth=2, label=f'Mean: {final_predictions.mean():.4f}')\nplt.xlabel('Predicted Accident Risk', fontsize=12)\nplt.ylabel('Count', fontsize=12)\nplt.title('Test Predictions Distribution', fontsize=14, fontweight='bold')\nplt.legend()\nplt.grid(axis='y', alpha=0.3)\n\nplt.subplot(1, 2, 2)\nplt.boxplot(final_predictions, vert=True)\nplt.ylabel('Predicted Accident Risk', fontsize=12)\nplt.title('Test Predictions - Box Plot', fontsize=14, fontweight='bold')\nplt.grid(axis='y', alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Save submission\nsubmission.to_csv('submission.csv', index=False)\nprint(\"\\n‚úÖ Submission file saved as 'submission.csv'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T20:40:05.600522Z","iopub.execute_input":"2025-10-29T20:40:05.600821Z","iopub.status.idle":"2025-10-29T20:40:06.136819Z","shell.execute_reply.started":"2025-10-29T20:40:05.600799Z","shell.execute_reply":"2025-10-29T20:40:06.135844Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}